{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read datasets\n",
    "## NOPD Calls datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Read Multiple CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_multiple_csvs_from_folder(folder_path, specific_columns):\n",
    "  \"\"\"Reads multiple CSV files from a folder and extracts specific columns.\n",
    "\n",
    "  Args:\n",
    "    folder_path: The path to the folder containing the CSV files.\n",
    "    specific_columns: A list of the specific columns to extract.\n",
    "\n",
    "  Returns:\n",
    "    A Pandas DataFrame containing the extracted data.\n",
    "  \"\"\"\n",
    "\n",
    "  # Get a list of all CSV files in the folder.\n",
    "  csv_files = glob.glob(os.path.join(folder_path + \"*.csv\"))\n",
    "\n",
    "  # Create an empty DataFrame to store the extracted data.\n",
    "  combined_df = pd.DataFrame()\n",
    "\n",
    "  # Loop through the list of CSV files and extract the specific columns.\n",
    "  for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[specific_columns]\n",
    "    combined_df = pd.concat([combined_df, df])\n",
    "\n",
    "  return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the function to create a combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First create the folder path\n",
    "current_working_dir = os.getcwd()\n",
    "relative_path = \"../data/raw-datasets/nopd-calls-csvs/\"\n",
    "folder_path = os.path.join(current_working_dir, relative_path)\n",
    "\n",
    "## List the columns to extract\n",
    "specific_columns = [\"NOPD_Item\", \"Type_\", \"TypeText\", \"Priority\", \n",
    "                    \"TimeCreate\", \"Location\"]\n",
    "\n",
    "## Call the function\n",
    "combined_df = read_multiple_csvs_from_folder(folder_path, specific_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create variable for domestic violence and domestic dispute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the type of calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DOMESTIC DISTURBANCE', 'DOMESTIC CRIMINAL DA', 'HOMICIDE DOMESTIC', 'SIMPLE BATTERY DOMESTIC', 'CRIMINAL DAMAGE DOMESTIC', 'EXTORTION (THREATS) DOMESTIC', 'AGGRAVATED BATTERY DOMESTIC', 'AGGRAVATED ASSAULT DOMESTIC', 'SIMPLE ASSAULT DOMESTIC', 'SIMPLE BURGLARY DOMESTIC', 'CRIMINAL MISCHIEF DOMESTIC', 'SIMPLE ARSON DOMESTIC', 'AGGRAVATED BURGLARY DOMESTIC', 'DOMESTIC VIOLENCE', 'DOMESTIC DISPUTE']\n"
     ]
    }
   ],
   "source": [
    "## Get the unique list of values in the \"TypeText\" column\n",
    "unique_types = combined_df[\"TypeText\"].unique()\n",
    "## Subset to unique types that contain \"DOMESTIC\"\n",
    "unique_type_domestic = [x for x in unique_types if \"DOMESTIC\" in x]\n",
    "print(unique_type_domestic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new variable that takes 1 if DOMESTIC VIOLENCE, 2 for DOMESTIC DISPUTE and 0 otherwise\n",
    "combined_df[\"domestic_violence\"] = combined_df[\"TypeText\"].apply(lambda x: 1 if \"DOMESTIC VIOLENCE\" in x else 2 if \"DOMESTIC DISPUTE\" in x else 3 if \"SIMPLE ASSAULT DOMESTIC\" in x else 0)\n",
    "combined_df[\"any_domestic\"] = combined_df[\"TypeText\"].apply(lambda x: 1 if \"DOMESTIC\" in x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "any_domestic\n",
       "0    5432130\n",
       "1     175737\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"any_domestic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "any_domestic\n",
       "0    96.866242\n",
       "1     3.133758\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"any_domestic\"].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_domestic = combined_df[combined_df[\"any_domestic\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeText\n",
       "DOMESTIC DISTURBANCE            63.384489\n",
       "SIMPLE BATTERY DOMESTIC         20.709355\n",
       "DOMESTIC DISPUTE                 5.080888\n",
       "CRIMINAL DAMAGE DOMESTIC         2.936775\n",
       "DOMESTIC VIOLENCE                2.694367\n",
       "AGGRAVATED ASSAULT DOMESTIC      1.573374\n",
       "EXTORTION (THREATS) DOMESTIC     1.415183\n",
       "AGGRAVATED BATTERY DOMESTIC      0.759089\n",
       "SIMPLE ASSAULT DOMESTIC          0.633902\n",
       "DOMESTIC CRIMINAL DA             0.542857\n",
       "SIMPLE BURGLARY DOMESTIC         0.128032\n",
       "AGGRAVATED BURGLARY DOMESTIC     0.107547\n",
       "CRIMINAL MISCHIEF DOMESTIC       0.017640\n",
       "HOMICIDE DOMESTIC                0.009674\n",
       "SIMPLE ARSON DOMESTIC            0.006828\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_domestic['TypeText'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domestic_violence\n",
       "0    5593089\n",
       "2       8929\n",
       "1       4735\n",
       "3       1114\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"domestic_violence\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domestic_violence\n",
       "0    99.736477\n",
       "2     0.159223\n",
       "1     0.084435\n",
       "3     0.019865\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"domestic_violence\"].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237060    POINT (-89.96808617 30.02749184)\n",
       "237061    POINT (-90.03178919 29.98638514)\n",
       "237062    POINT (-90.00302303 29.93189397)\n",
       "237063    POINT (-90.06480379 29.94325552)\n",
       "237064     POINT (-90.0373306 30.00297646)\n",
       "Name: Location, dtype: object"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['Location'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the string from the \"Location\" column that is between the two paranthesis\n",
    "import re\n",
    "\n",
    "# Convert the datatype of Location from float to string\n",
    "combined_df['Location_new'] = str(combined_df['Location'])\n",
    "\n",
    "# Define a regular expression to match the string between parentheses\n",
    "regex = r\"\\(.*?\\)\"\n",
    "\n",
    "# Create a new variable to store the extracted string\n",
    "extracted_string = []\n",
    "\n",
    "# Iterate over the existing column and extract the string between parentheses\n",
    "for row in combined_df['Location_new']:\n",
    "    match = re.search(regex, row)\n",
    "    if match:\n",
    "        extracted_string.append(match.group(0))\n",
    "    else:\n",
    "        extracted_string.append(None)\n",
    "\n",
    "# Create a new column and assign the extracted string to it\n",
    "combined_df['Location_new'] = extracted_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the latitude and longitude from the \"Location_new\" column by splitting the string based on space\n",
    "combined_df['Longitude'] = combined_df['Location_new'].str.split(' ').str[0]\n",
    "combined_df['Latitude'] = combined_df['Location_new'].str.split(' ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove paranthesis from the \"Longitude\" and \"Latitude\" columns\n",
    "### Longitude\n",
    "combined_df['Longitude'] = combined_df['Longitude'].str.replace('(', '')\n",
    "combined_df['Longitude'] = combined_df['Longitude'].str.replace(',', '')\n",
    "\n",
    "## Latitude\n",
    "combined_df['Latitude'] = combined_df['Latitude'].str.replace(')', '')\n",
    "combined_df['Latitude'] = combined_df['Latitude'].str.replace(')', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove 'e' from the \"Longitude\" and \"Latitude\" columns\n",
    "### Longitude\n",
    "combined_df['Longitude'] = combined_df['Longitude'].str.replace('E-', '')\n",
    "combined_df['Longitude'] = combined_df['Longitude'].str.replace('e-', '')\n",
    "\n",
    "## Latitude\n",
    "combined_df['Latitude'] = combined_df['Latitude'].str.replace('E-', '')\n",
    "combined_df['Latitude'] = combined_df['Latitude'].str.replace('e-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the datatype of the \"Longitude\" and \"Latitude\" columns from string to float\n",
    "combined_df['Longitude'] = combined_df['Longitude'].astype(float)\n",
    "combined_df['Latitude'] = combined_df['Latitude'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter cases where Lat or Long data is not in the NOLA range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nopd_clean = combined_df[(combined_df['Longitude'].abs() > 10) & (combined_df['Latitude'] > 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nopd_clean['Latitude'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['Latitude'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
